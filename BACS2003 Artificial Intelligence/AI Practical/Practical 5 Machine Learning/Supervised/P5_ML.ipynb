{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning and NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Classification Examples\n",
    "- Logistic Regression\n",
    "- Naive Bayes\n",
    "- Comparing Methods: Classification Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i163.photobucket.com/albums/t281/kyin_album/m1_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"blue\"> __Logistic Regression__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i163.photobucket.com/albums/t281/kyin_album/m6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Prepare the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure the data is labeled\n",
    "import pandas as pd\n",
    "data = pd.read_table('spam.txt',encoding='windows-1252', header=None)\n",
    "data.columns = ['label', 'text']\n",
    "print(data.head()) \n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove words with numbers, punctuation and capital letters\n",
    "import re\n",
    "import string\n",
    "alphanumeric = lambda x: re.sub(r\"\"\"\\w*\\d\\w*\"\"\", ' ', x)\n",
    "punc_lower = lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ', x.lower())\n",
    "data['text'] = data.text.map(alphanumeric).map(punc_lower)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Split the data (into training and testing set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Font color=\"Blue\">__Input__: Features, Predictors, Independent Variables, X's \n",
    "<Font color=\"orange\">__Outputs__: Label, Outcome, Dependent Variable, Y\n",
    "    \n",
    "![](https://i163.photobucket.com/albums/t281/kyin_album/m2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into feature and label\n",
    "X = data.text # inputs into model\n",
    "y = data.label # output of model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting\n",
    "\n",
    "![](https://i163.photobucket.com/albums/t281/kyin_album/m3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i163.photobucket.com/albums/t281/kyin_album/m4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data [Code]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into a training and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "# test size = 30% of observations, which means training size = 70% of observations\n",
    "# random state = 42, so we all get the same random train / test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Numerically encode the input data [Code]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(stop_words='english')\n",
    "X_train_cv = cv.fit_transform(X_train) \n",
    "X_test_cv = cv.transform(X_test) # transform uses the same vocab and one-hot encodes\n",
    "# print the dimensions of the training set (text messages, terms)\n",
    "print(X_train_cv.toarray().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(cv.fit_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Fit model and predict outcomes [Code]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "lr.fit(X_train_cv, y_train)\n",
    "\n",
    "# Take the model that was trained on the X_train_cv data and apply it to the X_test_cv\n",
    "y_pred_cv = lr.predict(X_test_cv)\n",
    "y_pred_cv # The output is all of the predictions/ labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i163.photobucket.com/albums/t281/kyin_album/m5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Evaluate the model [Code]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "cm = confusion_matrix(y_test, y_pred_cv)\n",
    "sns.heatmap(cm, xticklabels=['predicted_ham', 'predicted_spam'], yticklabels=['actual_ham', 'actual_spam'],\n",
    "annot=True, fmt='d', annot_kws={'fontsize':20}, cmap=\"YlGnBu\");\n",
    "true_neg, false_pos = cm[0]\n",
    "false_neg, true_pos = cm[1]\n",
    "accuracy = round((true_pos + true_neg) / (true_pos + true_neg + false_pos + false_neg),3)\n",
    "precision = round((true_pos) / (true_pos + false_pos),3)\n",
    "recall = round((true_pos) / (true_pos + false_neg),3)\n",
    "f1 = round(2 * (precision * recall) / (precision + recall),3)\n",
    "print('Accuracy: {}'.format(accuracy))\n",
    "print('Precision: {}'.format(precision))\n",
    "print('Recall: {}'.format(recall))\n",
    "print('F1 Score: {}'.format(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"blue\"> __Naive Bayes__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes [code]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a Naive Bayes model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import numpy as np\n",
    "nb = MultinomialNB()\n",
    "# Train the model\n",
    "nb.fit(X_train_cv, y_train)\n",
    "# Take the model that was trained on the X_train_cv data and apply it to the X_test_cv\n",
    "\n",
    "y_pred_cv_nb = nb.predict(X_test_cv)\n",
    "y_pred_cv_nb # The output is all of the predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes: Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_cv_nb)\n",
    "sns.heatmap(cm, xticklabels=['predicted_ham', 'predicted_spam'], yticklabels=['actual_ham', 'actual_spam'],\n",
    "annot=True, fmt='d', annot_kws={'fontsize':20}, cmap=\"YlGnBu\");\n",
    "true_neg, false_pos = cm[0]\n",
    "false_neg, true_pos = cm[1]\n",
    "accuracy = round((true_pos + true_neg) / (true_pos + true_neg + false_pos + false_neg),3)\n",
    "precision = round((true_pos) / (true_pos + false_pos),3)\n",
    "recall = round((true_pos) / (true_pos + false_neg),3)\n",
    "f1 = round(2 * (precision * recall) / (precision + recall),3)\n",
    "print('Accuracy: {}'.format(accuracy))\n",
    "print('Precision: {}'.format(precision))\n",
    "print('Recall: {}'.format(recall))\n",
    "print('F1 Score: {}'.format(f1))\n",
    "\n",
    "NBscore = nb.score(X_test_cv, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\"> Machine Learning and NLP Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "We will be using the same review data set from Kaggle for this exercise. The product we'll focus on this time is a cappuccino cup.\n",
    "\n",
    "The following code will help you load in the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('coffee.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1 \n",
    "\n",
    "- Determine how many reviews there are in total.\n",
    "\n",
    "\n",
    "Use the preprocessing code below to clean the reviews data before moving on to modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessing steps - remove numbers, captial letters and punctuation\n",
    "import re\n",
    "import string\n",
    "\n",
    "alphanumeric = lambda x: re.sub(r\"\"\"\\w*\\d\\w*\"\"\", ' ', x)\n",
    "punc_lower = lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ', x.lower())\n",
    "\n",
    "data['reviews'] = data.reviews.map(alphanumeric).map(punc_lower)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: Classsification *(20% testing, 80% training)*\n",
    "\n",
    "Processes for classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"Blue\">Step 1:</font> Prepare the data (identify the feature and label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"Blue\">Step 2:</font> Split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"Blue\">Step 3:</font> Vectorize the feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"Blue\">Step 4:</font> Idenfity the model/ classifier to be used. Feed the train data into the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -  Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"Blue\">Step 5:</font> Evaluate the Model - Accuracy Measurement\n",
    "Generate the accuracy scores for Linear Regression, SVM, Decision Tree, Random Forest, KNN, and Naive Bayes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Example Output:__\n",
    "- Accuracy score for LR  = 0.1651\n",
    "- Accuracy score for SVM = 0.5413\n",
    "- Accuracy score for DT  = 0.5505\n",
    "- Accuracy score for RF  = 0.5872\n",
    "- Accuracy score for KNN = 0.5963\n",
    "- Accuracy score for NB  = 0.6514"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "Predict the rate of this review, \n",
    "\n",
    "<font color=\"blue\">__\"I dislike this coffee, terrible taste and very greasy.\"__\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by using Linear Regression, SVM, Decision Tree, Random Forest, KNN, and Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
